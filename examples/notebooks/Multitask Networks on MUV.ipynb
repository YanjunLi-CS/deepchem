{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through the creation of multitask models on MUV. The goal is to demonstrate that multitask methods outperform singletask methods on MUV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb off\n",
    "reload = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of dataset: ['MUV-466' 'MUV-548' 'MUV-600' 'MUV-644' 'MUV-652' 'MUV-689' 'MUV-692'\n",
      " 'MUV-712' 'MUV-713' 'MUV-733' 'MUV-737' 'MUV-810' 'MUV-832' 'MUV-846'\n",
      " 'MUV-852' 'MUV-858' 'MUV-859' 'mol_id' 'smiles']\n",
      "Number of examples in dataset: 93127\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "\n",
    "dataset_file= \"../../datasets/muv.csv.gz\"\n",
    "dataset = dc.utils.save.load_from_disk(dataset_file)\n",
    "print(\"Columns of dataset: %s\" % str(dataset.columns.values))\n",
    "print(\"Number of examples in dataset: %s\" % str(dataset.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize some compounds from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test0.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test1.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test10.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test11.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test2.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test3.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test4.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test5.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test6.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test7.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test8.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test9.png' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from itertools import islice\n",
    "from IPython.display import Image, display, HTML\n",
    "\n",
    "def display_images(filenames):\n",
    "    \"\"\"Helper to pretty-print images.\"\"\"\n",
    "    imagesList=''.join(\n",
    "        [\"<img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='%s' />\"\n",
    "         % str(s) for s in sorted(filenames)])\n",
    "    display(HTML(imagesList))    \n",
    "\n",
    "def mols_to_pngs(mols, basename=\"test\"):\n",
    "    \"\"\"Helper to write RDKit mols to png files.\"\"\"\n",
    "    filenames = []\n",
    "    for i, mol in enumerate(mols):\n",
    "        filename = \"%s%d.png\" % (basename, i)\n",
    "        Draw.MolToFile(mol, filename)\n",
    "        filenames.append(filename)\n",
    "    return filenames\n",
    "\n",
    "num_to_display = 12\n",
    "molecules = []\n",
    "for _, data in islice(dataset.iterrows(), num_to_display):\n",
    "    molecules.append(Chem.MolFromSmiles(data[\"smiles\"]))\n",
    "display_images(mols_to_pngs(molecules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from ../../datasets/muv.csv.gz\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "Featurizing sample 8000\n",
      "TIMING: featurizing shard 0 took 22.680 s\n",
      "Loading shard 2 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "Featurizing sample 8000\n",
      "TIMING: featurizing shard 1 took 31.196 s\n",
      "Loading shard 3 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "Featurizing sample 8000\n",
      "TIMING: featurizing shard 2 took 29.828 s\n",
      "Loading shard 4 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "Featurizing sample 8000\n",
      "TIMING: featurizing shard 3 took 16.055 s\n",
      "Loading shard 5 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "Featurizing sample 8000\n",
      "TIMING: featurizing shard 4 took 21.150 s\n",
      "Loading shard 6 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "Featurizing sample 8000\n",
      "TIMING: featurizing shard 5 took 16.878 s\n",
      "Loading shard 7 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "Featurizing sample 8000\n",
      "TIMING: featurizing shard 6 took 16.032 s\n",
      "Loading shard 8 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "Featurizing sample 8000\n",
      "TIMING: featurizing shard 7 took 16.518 s\n",
      "Loading shard 9 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "Featurizing sample 8000\n",
      "TIMING: featurizing shard 8 took 17.401 s\n",
      "Loading shard 10 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "Featurizing sample 8000\n",
      "TIMING: featurizing shard 9 took 21.326 s\n",
      "Loading shard 11 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "Featurizing sample 8000\n",
      "TIMING: featurizing shard 10 took 23.441 s\n",
      "Loading shard 12 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "TIMING: featurizing shard 11 took 8.318 s\n",
      "TIMING: dataset construction took 246.032 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "MUV_tasks = ['MUV-692', 'MUV-689', 'MUV-846', 'MUV-859', 'MUV-644',\n",
    "             'MUV-548', 'MUV-852', 'MUV-600', 'MUV-810', 'MUV-712',\n",
    "             'MUV-737', 'MUV-858', 'MUV-713', 'MUV-733', 'MUV-652',\n",
    "             'MUV-466', 'MUV-832']\n",
    "\n",
    "featurizer = dc.feat.CircularFingerprint(size=1024)\n",
    "loader = dc.data.CSVLoader(\n",
    "      tasks=MUV_tasks, smiles_field=\"smiles\",\n",
    "      featurizer=featurizer)\n",
    "dataset = loader.featurize(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing train/valid/test indices\n",
      "TIMING: dataset construction took 6.272 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 3.243 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 3.498 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "splitter = dc.splits.RandomSplitter(dataset_file)\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(\n",
    "    dataset)\n",
    "#NOTE THE RENAMING:\n",
    "valid_dataset, test_dataset = test_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1/1\n",
      "hyperparameters: {'learning_rate': 0.001, 'layer_sizes': (1000,), 'data_shape': (1024,), 'dropouts': (0.5,), 'activation': 'relu', 'decay': 1e-06, 'batch_size': 50, 'penalty': 0.0, 'nesterov': False, 'init': 'glorot_uniform', 'bias_init_consts': (1.0,), 'weight_init_stddevs': (0.1,), 'batchnorm': False, 'nb_layers': 1, 'nb_epoch': 1, 'momentum': 0.9}\n",
      "Training for 1 epochs\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "On batch 1100\n",
      "On batch 1150\n",
      "On batch 1200\n",
      "On batch 1250\n",
      "On batch 1300\n",
      "On batch 1350\n",
      "On batch 1400\n",
      "On batch 1450\n",
      "Ending epoch 0: Average loss 0.0517954\n",
      "On batch 0\n",
      "TIMING: model fitting took 42.847 s True\n",
      "computed_metrics: [0.65548567435359884, 0.3938885157824043, 0.91541865214431595, 0.39478957915831664, 0.68465248721524885, 0.74978870858688307, 0.80529733424470273, 0.77885952712100137, 0.79980310400741261, 0.88896680691912111, 0.5185931899641576, 0.5150129017124091, 0.75240054869684503, 0.36638813096862211, 0.58238095238095244, 0.61817558299039777, 0.68414343983684567]\n",
      "Model 1/1, Metric mean-roc_auc_score, Validation set 0: 0.653179\n",
      "\tbest_validation_score so far: 0.653179\n",
      "computed_metrics: [0.9154553963735379, 0.93463278293773655, 0.98457975954502508, 0.93589327852250226, 0.97265932420872547, 0.9838091436190004, 0.97946596833011079, 0.92610806949042246, 0.88254565136882901, 0.94433074824070085, 0.93797633429015803, 0.94311234732601956, 0.93923263973993476, 0.94550404459919302, 0.90309495615889945, 0.87384089962146405, 0.99468966106036016]\n",
      "Best hyperparameters: (1e-06, (1024,), 1, 'relu', (1000,), 50, 0.0, False, 'glorot_uniform', (1.0,), (0.1,), 1, False, (0.5,), 0.001, 0.9)\n",
      "train_score: 0.940996\n",
      "validation_score: 0.653179\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random\n",
    "\n",
    "params_dict = {\"activation\": [\"relu\"],\n",
    "               \"momentum\": [.9],\n",
    "               \"batch_size\": [50],\n",
    "               \"init\": [\"glorot_uniform\"],\n",
    "               \"data_shape\": [train_dataset.get_data_shape()],\n",
    "               \"learning_rate\": [1e-3],\n",
    "               \"decay\": [1e-6],\n",
    "               \"nb_epoch\": [1],\n",
    "               \"nesterov\": [False],\n",
    "               \"dropouts\": [(.5,)],\n",
    "               \"nb_layers\": [1],\n",
    "               \"batchnorm\": [False],\n",
    "               \"layer_sizes\": [(1000,)],\n",
    "               \"weight_init_stddevs\": [(.1,)],\n",
    "               \"bias_init_consts\": [(1.,)],\n",
    "               \"penalty\": [0.], \n",
    "              } \n",
    "\n",
    "\n",
    "n_features = train_dataset.get_data_shape()[0]\n",
    "def model_builder(model_params, model_dir):\n",
    "  model = dc.models.TensorflowMultiTaskClassifier(\n",
    "    len(MUV_tasks), n_features, **model_params)\n",
    "  return model\n",
    "\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
    "optimizer = dc.hyper.HyperparamOpt(model_builder)\n",
    "best_dnn, best_hyperparams, all_results = optimizer.hyperparam_search(\n",
    "    params_dict, train_dataset, valid_dataset, [], metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
